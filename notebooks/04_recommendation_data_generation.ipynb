{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ffe6f8",
   "metadata": {},
   "source": [
    "# Lipstick Recommendation Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a3c1b",
   "metadata": {},
   "source": [
    "This notebook processes the clustered lipstick data and generates a structured dataset.\n",
    "\n",
    "## Process Overview:\n",
    "1. Load and preprocess lipstick product data\n",
    "2. Process URLs and clean data\n",
    "3. Analyze color patterns and create clusters\n",
    "4. Generate recommendation scores\n",
    "5. Export frontend-ready dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7087f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from typing import Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1513c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Configuration\n",
    "CLUSTER_NAMES = {\n",
    "    0: 'Warm Brown',\n",
    "    1: 'Soft Pink', \n",
    "    2: 'Nude',\n",
    "    3: 'Classic Red',\n",
    "    4: 'Deep Burgundy',\n",
    "    5: 'Coral Pink'\n",
    "}\n",
    "\n",
    "RATING_WEIGHT = 0.7\n",
    "REVIEW_WEIGHT = 0.3\n",
    "\n",
    "DATA_PATH = \"processed_data/metadata_with_assets_feedback.pkl\"\n",
    "MODEL_PATH = \"trained_models/sephora_lipstick_clustering_model.pkl\"\n",
    "OUTPUT_PATH = \"dataset/lipstick_recommendation_dataset.csv\"\n",
    "\n",
    "TOP_N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09f64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipstickDataProcessor:\n",
    "    \"\"\"Process and analyze lipstick product data with color information.\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"Initialize with data file path.\"\"\"\n",
    "        self.df = pd.read_pickle(file_path)\n",
    "        self.processed_df = None\n",
    "        \n",
    "    def process_urls(self) -> None:\n",
    "        \"\"\"Process and update product URLs.\"\"\"\n",
    "        def update_sku_url(row: pd.Series) -> str:\n",
    "            base_url = row['targetUrl']\n",
    "            updated_url = re.sub(r'skuId=\\d+', f'skuId={row[\"skuID\"]}', base_url)\n",
    "            return updated_url\n",
    "            \n",
    "        self.df['processed_url'] = self.df.apply(update_sku_url, axis=1)\n",
    "        self.df['full_url'] = 'https://www.sephora.com' + self.df['processed_url']\n",
    "        self.df.drop('processed_url', axis=1, inplace=True)\n",
    "        \n",
    "    def clean_data(self) -> None:\n",
    "        \"\"\"Clean and prepare the data for analysis.\"\"\"\n",
    "        # Drop rows with missing skin tone\n",
    "        self.df = self.df.dropna(subset=['ContextDataValues.skinTone.ValueLabel'])\n",
    "        \n",
    "        # Remove 'notSure' skin tone responses\n",
    "        self.df = self.df[self.df['ContextDataValues.skinTone.ValueLabel'] != 'notSure']\n",
    "        \n",
    "        # Drop rows with invalid RGB values\n",
    "        self.df = self.df[~self.df['avg_rgb'].apply(lambda x: np.array_equal(x, [0, 0, 0]))]\n",
    "        self.df = self.df.dropna(subset=['avg_rgb'])\n",
    "        \n",
    "        # Standardize skin tone labels\n",
    "        self.df['ContextDataValues.skinTone.ValueLabel'] = self.df['ContextDataValues.skinTone.ValueLabel'].replace({\n",
    "            'Ebony': 'Rich',\n",
    "            'Olive': 'Tan'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8720d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorAnalyzer:\n",
    "    \"\"\"Analyze color patterns and create color clusters with cross validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.n_clusters = 10\n",
    "        self.optimal_k = 10\n",
    "        self.kmeans_model = None\n",
    "        self.cluster_labels = None\n",
    "        self.cv_results = None\n",
    "\n",
    "def load_analyzer(file_path: str = 'trained_models/sephora_lipstick_clustering_model.pkl') -> ColorAnalyzer:\n",
    "    \"\"\"Load a pre-trained color analyzer.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3725215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_base64_image(base64_str: str) -> bool:\n",
    "    \"\"\"Validate if string is a valid base64 encoded image.\n",
    "    \n",
    "    Args:\n",
    "        base64_str: Base64 encoded string\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid image, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(base64_str, str):\n",
    "            return False\n",
    "        img_data = base64.b64decode(base64_str)\n",
    "        Image.open(BytesIO(img_data))\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00420a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationDataGenerator:\n",
    "    \"\"\"Process and generate recommendation data for frontend consumption.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_processor: LipstickDataProcessor, model_path: str):\n",
    "        \"\"\"Initialize data generator with processor and model.\"\"\"\n",
    "        self.df = data_processor.df\n",
    "        self.processor = data_processor\n",
    "        self.analyzer = load_analyzer(model_path)\n",
    "        self.frontend_df = None\n",
    "            \n",
    "    def process_color_data(self) -> None:\n",
    "        \"\"\"Process and normalize color data.\"\"\"\n",
    "        # Normalize RGB values\n",
    "        self.df[['R', 'G', 'B']] = pd.DataFrame(\n",
    "            self.df['avg_rgb'].tolist(),\n",
    "            index=self.df.index\n",
    "        ) / 255.0\n",
    "        \n",
    "        # Add cluster predictions\n",
    "        X = self.df[['R', 'G', 'B']].values\n",
    "        self.df['color_cluster'] = self.analyzer.kmeans_model.predict(X)\n",
    "        self.df['cluster_name'] = self.df['color_cluster'].map(CLUSTER_NAMES)\n",
    "        \n",
    "    def calculate_recommendation_score(self, row: pd.Series) -> float:\n",
    "        \"\"\"Calculate product recommendation score.\"\"\"\n",
    "        try:\n",
    "            rating = float(row['Rating'])\n",
    "            rating_score = rating / 5.0\n",
    "\n",
    "            reviews = int(row['reviews'])\n",
    "            max_reviews = int(self.df['reviews'].max())\n",
    "\n",
    "            reviews_float = np.float64(reviews)\n",
    "            max_reviews_float = np.float64(max_reviews)\n",
    "            review_score = np.log1p(reviews_float) / np.log1p(max_reviews_float)\n",
    "            final_score = (RATING_WEIGHT * rating_score + REVIEW_WEIGHT * review_score)\n",
    "\n",
    "            return round(final_score * 100, 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError calculating score for product:\")\n",
    "            print(f\"SKU ID: {row['skuID']}\")\n",
    "            print(f\"Rating: {row['Rating']} ({type(row['Rating'])})\")\n",
    "            print(f\"Reviews: {row['reviews']} ({type(row['reviews'])})\")\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def filter_valid_images(self) -> None:\n",
    "        \"\"\"Filter out records with invalid image data.\"\"\"\n",
    "        # Check both cover and lipstick images\n",
    "        valid_images = (\n",
    "            pd.notna(self.df['cover_image_base64']) & \n",
    "            pd.notna(self.df['lipstick_image_base64']) &\n",
    "            self.df['cover_image_base64'].apply(is_valid_base64_image) &\n",
    "            self.df['lipstick_image_base64'].apply(is_valid_base64_image)\n",
    "        )\n",
    "        self.df = self.df[valid_images].copy()\n",
    "        print(f\"Filtered to {len(self.df)} records with valid images\")\n",
    "\n",
    "    def prepare_frontend_data(self, top_n: int = 50, min_products_per_cluster: int = 50) -> None:\n",
    "        \"\"\"Prepare and structure data for frontend use.\"\"\"\n",
    "        # Select relevant columns\n",
    "        frontend_cols = [\n",
    "            'skuID',\n",
    "            'brandName',\n",
    "            'displayName',\n",
    "            'color_description',\n",
    "            'color_cluster',\n",
    "            'cluster_name',\n",
    "            'avg_rgb',\n",
    "            'Rating',\n",
    "            'reviews',\n",
    "            'currentSku.listPrice',\n",
    "            'full_url',\n",
    "            'cover_image_base64',\n",
    "            'lipstick_image_base64'\n",
    "        ]\n",
    "        \n",
    "        self.frontend_df = self.df[frontend_cols].copy()\n",
    "  \n",
    "        # Remove duplicates based on 'skuID'\n",
    "        self.frontend_df = self.frontend_df.drop_duplicates(subset=['skuID'])\n",
    "        \n",
    "        # Add RGB string format\n",
    "        self.frontend_df['rgb_value'] = self.frontend_df['avg_rgb'].apply(\n",
    "            lambda x: f\"rgb({int(x[0])},{int(x[1])},{int(x[2])})\"\n",
    "        )\n",
    "        \n",
    "        # Add recommendation scores\n",
    "        self.frontend_df['recommendation_score'] = self.frontend_df.apply(\n",
    "            self.calculate_recommendation_score, axis=1\n",
    "        )\n",
    "        \n",
    "        # Get top N recommendations per cluster\n",
    "        self.frontend_df = (self.frontend_df\n",
    "            .groupby('color_cluster')\n",
    "            .apply(lambda x: x.nlargest(top_n, 'recommendation_score'))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        \n",
    "        # Ensure each cluster has at least min_products_per_cluster products\n",
    "        self._ensure_minimum_products_per_cluster(min_products_per_cluster)\n",
    "\n",
    "    def _ensure_minimum_products_per_cluster(self, min_products: int):\n",
    "        \"\"\"Ensure each cluster has at least `min_products` unique products.\"\"\"\n",
    "        adjusted_clusters = []\n",
    "\n",
    "        all_skuIDs = set(self.frontend_df['skuID'])\n",
    "        \n",
    "        # Get the minimum recommendation_score per cluster\n",
    "        min_scores = self.frontend_df.groupby('color_cluster')['recommendation_score'].min().to_dict()\n",
    "\n",
    "        for cluster_id, group in self.frontend_df.groupby('color_cluster'):\n",
    "            cluster_size = len(group)\n",
    "            print(f\"Cluster {cluster_id} has {cluster_size} products.\")\n",
    "            \n",
    "            if cluster_size >= min_products:\n",
    "                # If the cluster has enough products, keep it as is\n",
    "                adjusted_clusters.append(group)\n",
    "            else:\n",
    "                num_to_add = min_products - cluster_size\n",
    "                print(f\"Cluster {cluster_id} needs {num_to_add} more products.\")\n",
    "                \n",
    "                # Get products from other clusters, excluding those already in any cluster\n",
    "                other_clusters = self.frontend_df[self.frontend_df['color_cluster'] != cluster_id]\n",
    "                \n",
    "                # Exclude products already in the cluster\n",
    "                existing_skuIDs = set(group['skuID'])\n",
    "                available_products = other_clusters[~other_clusters['skuID'].isin(existing_skuIDs)]\n",
    "                \n",
    "                # Sort available products by recommendation_score descending\n",
    "                available_products = available_products.sort_values(\n",
    "                    'recommendation_score', ascending=False\n",
    "                )\n",
    "                \n",
    "                # Select top N products to add\n",
    "                products_to_add = available_products.head(num_to_add).copy()\n",
    "                \n",
    "                # Adjust the recommendation_score to be less than the minimum in the cluster\n",
    "                if cluster_id in min_scores:\n",
    "                    min_score = min_scores[cluster_id]\n",
    "                    # Subtract a small value to ensure it's less\n",
    "                    products_to_add['recommendation_score'] = min_score - 0.01\n",
    "                else:\n",
    "                    # If no existing score, set to a default low value\n",
    "                    products_to_add['recommendation_score'] = 0.0\n",
    "                \n",
    "                # Update the cluster_id and cluster_name to the current cluster\n",
    "                products_to_add['color_cluster'] = cluster_id\n",
    "                products_to_add['cluster_name'] = CLUSTER_NAMES.get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "                \n",
    "                # Add the products to the cluster\n",
    "                adjusted_group = pd.concat([group, products_to_add], ignore_index=True)\n",
    "                adjusted_clusters.append(adjusted_group)\n",
    "        \n",
    "        # Combine all clusters back into frontend_df\n",
    "        self.frontend_df = pd.concat(adjusted_clusters, ignore_index=True)\n",
    "        \n",
    "    def export_data(self, output_path: str) -> None:\n",
    "        \"\"\"Export processed data to CSV.\"\"\"\n",
    "        # Ensure all required columns are present\n",
    "        required_cols = [\n",
    "            'skuID',\n",
    "            'brandName',\n",
    "            'displayName',\n",
    "            'color_description',\n",
    "            'color_cluster',\n",
    "            'cluster_name',\n",
    "            'rgb_value',\n",
    "            'Rating',\n",
    "            'reviews',\n",
    "            'currentSku.listPrice',\n",
    "            'full_url',\n",
    "            'cover_image_base64',\n",
    "            'lipstick_image_base64',\n",
    "            'recommendation_score'\n",
    "        ]\n",
    "        \n",
    "        export_df = self.frontend_df[required_cols]\n",
    "        \n",
    "        # Add metadata\n",
    "        export_df.attrs['generated_date'] = datetime.now().isoformat()\n",
    "        export_df.attrs['total_products'] = len(export_df)\n",
    "        export_df.attrs['cluster_counts'] = export_df['cluster_name'].value_counts().to_dict()\n",
    "        \n",
    "        # Export to CSV\n",
    "        export_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"Data Export Summary:\")\n",
    "        print(f\"Total products processed: {len(export_df):,}\")\n",
    "        print(\"\\nCluster Distribution:\")\n",
    "        for name, count in export_df['cluster_name'].value_counts().items():\n",
    "            print(f\"{name}: {count:,} products ({count/len(export_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2aea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Processor and Generator\n",
    "processor = LipstickDataProcessor(DATA_PATH)\n",
    "processor.process_urls()\n",
    "processor.clean_data()\n",
    "\n",
    "# Process pipeline\n",
    "generator = RecommendationDataGenerator(processor, MODEL_PATH)\n",
    "\n",
    "print(\"Processing data...\")\n",
    "generator.process_color_data()\n",
    "\n",
    "print(\"Filtering valid images...\")\n",
    "generator.filter_valid_images()\n",
    "\n",
    "print(\"Preparing frontend data...\")\n",
    "generator.prepare_frontend_data(top_n=TOP_N)\n",
    "\n",
    "print(\"Exporting data...\")\n",
    "generator.export_data(OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env39",
   "language": "python",
   "name": "env39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
